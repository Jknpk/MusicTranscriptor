{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Convolutional Neural Network - TensorFlow </h1><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data)\n",
    "\n",
    "#print(\"Size of:\")\n",
    "#print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "#print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "#print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Placeholder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-73aff66ff391>:8: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "# Placeholder variable for the input images\n",
    "x = tf.placeholder(tf.float32, shape=[None, 224*224], name='X')\n",
    "# Reshape it into [num_images, img_height, img_width, num_channels]\n",
    "x_image = tf.reshape(x, [-1, 224, 224, 1])\n",
    "\n",
    "# Placeholder variable for the true labels associated with the images\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 88], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for creating a new Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input, num_input_channels, filter_size, num_filters, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # Shape of the filter-weights for the convolution\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "        # Create new weights (filters) with the given shape\n",
    "        weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "        # Create new biases, one for each filter\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.conv2d(input=input, filter=weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # Add the biases to the results of the convolution.\n",
    "        layer += biases\n",
    "        \n",
    "        return layer, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for creating a new Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_pool_layer(input, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.max_pool(value=input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for creating a new ReLU Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_relu_layer(input, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.relu(input)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for creating a new Fully connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input, num_inputs, num_outputs, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "\n",
    "        # Create new weights and biases.\n",
    "        weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "        \n",
    "        # Multiply the input and weights, and then add the bias-values.\n",
    "        layer = tf.matmul(input, weights) + biases\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features:\n",
      "4704\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Layer 1\n",
    "layer_conv1, weights_conv1 = new_conv_layer(input=x_image, num_input_channels=1, filter_size=5, num_filters=6, name =\"conv1\")\n",
    "\n",
    "# Pooling Layer 1\n",
    "layer_pool1 = new_pool_layer(layer_conv1, name=\"pool1\")\n",
    "\n",
    "# RelU layer 1\n",
    "layer_relu1 = new_relu_layer(layer_pool1, name=\"relu1\")\n",
    "\n",
    "# Convolutional Layer 2\n",
    "layer_conv2, weights_conv2 = new_conv_layer(input=layer_relu1, num_input_channels=6, filter_size=5, num_filters=12, name= \"conv2\")\n",
    "\n",
    "# Pooling Layer 2\n",
    "layer_pool2 = new_pool_layer(layer_conv2, name=\"pool2\")\n",
    "\n",
    "# RelU layer 2\n",
    "layer_relu2 = new_relu_layer(layer_pool2, name=\"relu2\")\n",
    "\n",
    "# Convolutional Layer 3\n",
    "layer_conv3, weights_conv3 = new_conv_layer(input=layer_relu2, num_input_channels=12, filter_size=5, num_filters=24, name= \"conv3\")\n",
    "\n",
    "# Pooling Layer 3\n",
    "layer_pool3 = new_pool_layer(layer_conv3, name=\"pool3\")\n",
    "\n",
    "# RelU layer 3\n",
    "layer_relu3 = new_relu_layer(layer_pool3, name=\"relu3\")\n",
    "\n",
    "# Convolutional Layer 4\n",
    "layer_conv4, weights_conv4 = new_conv_layer(input=layer_relu3, num_input_channels=24, filter_size=5, num_filters=48, name= \"conv4\")\n",
    "\n",
    "# Pooling Layer 4\n",
    "layer_pool4 = new_pool_layer(layer_conv4, name=\"pool4\")\n",
    "\n",
    "# RelU layer 4\n",
    "layer_relu4 = new_relu_layer(layer_pool4, name=\"relu4\")\n",
    "\n",
    "# Convolutional Layer 5\n",
    "layer_conv5, weights_conv5 = new_conv_layer(input=layer_relu4, num_input_channels=48, filter_size=5, num_filters=96, name= \"conv5\")\n",
    "\n",
    "# Pooling Layer 5\n",
    "layer_pool5 = new_pool_layer(layer_conv5, name=\"pool5\")\n",
    "\n",
    "# RelU layer 5\n",
    "layer_relu5 = new_relu_layer(layer_pool5, name=\"relu5\")\n",
    "\n",
    "# Flatten Layer\n",
    "num_features = layer_relu5.get_shape()[1:4].num_elements()\n",
    "layer_flat = tf.reshape(layer_relu5, [-1, num_features])\n",
    "\n",
    "print(\"Num Features:\")\n",
    "print(num_features)                             \n",
    "                             \n",
    "# Fully-Connected Layer 1\n",
    "layer_fc1 = new_fc_layer(layer_flat, num_inputs=num_features, num_outputs=1000, name=\"fc1\")\n",
    "\n",
    "# RelU layer 3\n",
    "layer_relu6 = new_relu_layer(layer_fc1, name=\"relu6\")\n",
    "\n",
    "# Fully-Connected Layer 2\n",
    "layer_fc2 = new_fc_layer(input=layer_relu6, num_inputs=1000, num_outputs=88, name=\"fc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Softmax function to normalize the output\n",
    "with tf.variable_scope(\"Softmax\"):\n",
    "    y_pred = tf.nn.softmax(layer_fc2)\n",
    "    y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-0fd2322922db>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Cross entropy cost function\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)\n",
    "    cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Adam Optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_prediction\n",
    "with tf.name_scope(\"correct_prediction\"):\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(\"Training_FileWriter/\")\n",
    "writer1 = tf.summary.FileWriter(\"Validation_FileWriter/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cost and accuracy to summary\n",
    "tf.summary.scalar('loss', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 88\n",
    "data_path = 'train.tfrecords'  # address to save the hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast_5:0\", shape=(), dtype=int32)\n",
      "epoch: 0\n",
      "Train accuracy on batch 0.01136\n",
      "Epoch 1 completed : Time usage 0.8 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.01\n",
      "epoch: 1\n",
      "Train accuracy on batch 0.01136\n",
      "Epoch 2 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.01\n",
      "epoch: 2\n",
      "Train accuracy on batch 0.03409\n",
      "Epoch 3 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.03\n",
      "epoch: 3\n",
      "Train accuracy on batch 0.01136\n",
      "Epoch 4 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.01\n",
      "epoch: 4\n",
      "Train accuracy on batch 0.01136\n",
      "Epoch 5 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.01\n",
      "epoch: 5\n",
      "Train accuracy on batch 0.02273\n",
      "Epoch 6 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.02\n",
      "epoch: 6\n",
      "Train accuracy on batch 0.01136\n",
      "Epoch 7 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.01\n",
      "epoch: 7\n",
      "Train accuracy on batch 0.01136\n",
      "Epoch 8 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.01\n",
      "epoch: 8\n",
      "Train accuracy on batch 0.03409\n",
      "Epoch 9 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.03\n",
      "epoch: 9\n",
      "Train accuracy on batch 0.03409\n",
      "Epoch 10 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.03\n",
      "epoch: 10\n",
      "Train accuracy on batch 0.05682\n",
      "Epoch 11 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.06\n",
      "epoch: 11\n",
      "Train accuracy on batch 0.03409\n",
      "Epoch 12 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.03\n",
      "epoch: 12\n",
      "Train accuracy on batch 0.02273\n",
      "Epoch 13 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.02\n",
      "epoch: 13\n",
      "Train accuracy on batch 0.04545\n",
      "Epoch 14 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.05\n",
      "epoch: 14\n",
      "Train accuracy on batch 0.04545\n",
      "Epoch 15 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.05\n",
      "epoch: 15\n",
      "Train accuracy on batch 0.04545\n",
      "Epoch 16 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.05\n",
      "epoch: 16\n",
      "Train accuracy on batch 0.06818\n",
      "Epoch 17 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.07\n",
      "epoch: 17\n",
      "Train accuracy on batch 0.05682\n",
      "Epoch 18 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.06\n",
      "epoch: 18\n",
      "Train accuracy on batch 0.05682\n",
      "Epoch 19 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.06\n",
      "epoch: 19\n",
      "Train accuracy on batch 0.04545\n",
      "Epoch 20 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.05\n",
      "epoch: 20\n",
      "Train accuracy on batch 0.05682\n",
      "Epoch 21 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.06\n",
      "epoch: 21\n",
      "Train accuracy on batch 0.10227\n",
      "Epoch 22 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.1\n",
      "epoch: 22\n",
      "Train accuracy on batch 0.05682\n",
      "Epoch 23 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.06\n",
      "epoch: 23\n",
      "Train accuracy on batch 0.06818\n",
      "Epoch 24 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.07\n",
      "epoch: 24\n",
      "Train accuracy on batch 0.09091\n",
      "Epoch 25 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.09\n",
      "epoch: 25\n",
      "Train accuracy on batch 0.10227\n",
      "Epoch 26 completed : Time usage 0.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.1\n",
      "epoch: 26\n",
      "Train accuracy on batch 0.14773\n",
      "Epoch 27 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.15\n",
      "epoch: 27\n",
      "Train accuracy on batch 0.17045\n",
      "Epoch 28 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.17\n",
      "epoch: 28\n",
      "Train accuracy on batch 0.21591\n",
      "Epoch 29 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.22\n",
      "epoch: 29\n",
      "Train accuracy on batch 0.25\n",
      "Epoch 30 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.25\n",
      "epoch: 30\n",
      "Train accuracy on batch 0.30682\n",
      "Epoch 31 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.31\n",
      "epoch: 31\n",
      "Train accuracy on batch 0.29545\n",
      "Epoch 32 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.3\n",
      "epoch: 32\n",
      "Train accuracy on batch 0.28409\n",
      "Epoch 33 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.28\n",
      "epoch: 33\n",
      "Train accuracy on batch 0.32955\n",
      "Epoch 34 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.33\n",
      "epoch: 34\n",
      "Train accuracy on batch 0.38636\n",
      "Epoch 35 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.39\n",
      "epoch: 35\n",
      "Train accuracy on batch 0.40909\n",
      "Epoch 36 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.41\n",
      "epoch: 36\n",
      "Train accuracy on batch 0.48864\n",
      "Epoch 37 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.49\n",
      "epoch: 37\n",
      "Train accuracy on batch 0.5\n",
      "Epoch 38 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.5\n",
      "epoch: 38\n",
      "Train accuracy on batch 0.53409\n",
      "Epoch 39 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.53\n",
      "epoch: 39\n",
      "Train accuracy on batch 0.56818\n",
      "Epoch 40 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.57\n",
      "epoch: 40\n",
      "Train accuracy on batch 0.56818\n",
      "Epoch 41 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.57\n",
      "epoch: 41\n",
      "Train accuracy on batch 0.64773\n",
      "Epoch 42 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.65\n",
      "epoch: 42\n",
      "Train accuracy on batch 0.625\n",
      "Epoch 43 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.62\n",
      "epoch: 43\n",
      "Train accuracy on batch 0.65909\n",
      "Epoch 44 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.66\n",
      "epoch: 44\n",
      "Train accuracy on batch 0.69318\n",
      "Epoch 45 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.69\n",
      "epoch: 45\n",
      "Train accuracy on batch 0.70455\n",
      "Epoch 46 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.7\n",
      "epoch: 46\n",
      "Train accuracy on batch 0.73864\n",
      "Epoch 47 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.74\n",
      "epoch: 47\n",
      "Train accuracy on batch 0.81818\n",
      "Epoch 48 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.82\n",
      "epoch: 48\n",
      "Train accuracy on batch 0.84091\n",
      "Epoch 49 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.84\n",
      "epoch: 49\n",
      "Train accuracy on batch 0.86364\n",
      "Epoch 50 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.86\n",
      "epoch: 50\n",
      "Train accuracy on batch 0.92045\n",
      "Epoch 51 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.92\n",
      "epoch: 51\n",
      "Train accuracy on batch 0.88636\n",
      "Epoch 52 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.89\n",
      "epoch: 52\n",
      "Train accuracy on batch 0.89773\n",
      "Epoch 53 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.9\n",
      "epoch: 53\n",
      "Train accuracy on batch 0.89773\n",
      "Epoch 54 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.9\n",
      "epoch: 54\n",
      "Train accuracy on batch 0.92045\n",
      "Epoch 55 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.92\n",
      "epoch: 55\n",
      "Train accuracy on batch 0.90909\n",
      "Epoch 56 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.91\n",
      "epoch: 56\n",
      "Train accuracy on batch 0.95455\n",
      "Epoch 57 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.95\n",
      "epoch: 57\n",
      "Train accuracy on batch 0.94318\n",
      "Epoch 58 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.94\n",
      "epoch: 58\n",
      "Train accuracy on batch 0.94318\n",
      "Epoch 59 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.94\n",
      "epoch: 59\n",
      "Train accuracy on batch 0.97727\n",
      "Epoch 60 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.98\n",
      "epoch: 60\n",
      "Train accuracy on batch 0.96591\n",
      "Epoch 61 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.97\n",
      "epoch: 61\n",
      "Train accuracy on batch 0.95455\n",
      "Epoch 62 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.95\n",
      "epoch: 62\n",
      "Train accuracy on batch 0.97727\n",
      "Epoch 63 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.98\n",
      "epoch: 63\n",
      "Train accuracy on batch 0.97727\n",
      "Epoch 64 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.98\n",
      "epoch: 64\n",
      "Train accuracy on batch 0.97727\n",
      "Epoch 65 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.98\n",
      "epoch: 65\n",
      "Train accuracy on batch 0.97727\n",
      "Epoch 66 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.98\n",
      "epoch: 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy on batch 0.97727\n",
      "Epoch 67 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.98\n",
      "epoch: 67\n",
      "Train accuracy on batch 0.97727\n",
      "Epoch 68 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.98\n",
      "epoch: 68\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 69 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 69\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 70 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 70\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 71 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 71\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 72 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 72\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 73 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 73\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 74 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 74\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 75 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 75\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 76 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 76\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 77 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 77\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 78 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 78\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 79 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 79\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 80 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 80\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 81 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 81\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 82 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 82\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 83 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 83\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 84 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 84\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 85 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 85\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 86 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 86\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 87 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 87\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 88 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 88\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 89 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 89\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 90 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 90\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 91 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 91\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 92 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 92\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 93 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 93\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 94 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 94\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 95 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 95\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 96 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 96\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 97 completed : Time usage 0.25 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 97\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 98 completed : Time usage 0.24 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 98\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 99 completed : Time usage 0.23 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 99\n",
      "Train accuracy on batch 0.98864\n",
      "Epoch 100 completed : Time usage 0.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "corresponding label:  72\n",
      "[72]\n",
      "wrote test-dataset stuff into <tensorflow.python.summary.writer.writer.FileWriter object at 0x7f7d5bf4f160>\n"
     ]
    }
   ],
   "source": [
    "#tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    \n",
    "    feature = {'train/image': tf.FixedLenFeature([], tf.string),\n",
    "               'train/label': tf.FixedLenFeature([], tf.int64)}\n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([data_path], num_epochs=num_epochs)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['train/image'], tf.uint8)\n",
    "    \n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['train/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, [224, 224])\n",
    "    \n",
    "    print(label)\n",
    "    \n",
    "    # Any preprocessing here ...\n",
    "    \n",
    "    # Creates batches by randomly shuffling tensors\n",
    "    images, labels = tf.train.shuffle_batch([image, label], batch_size=batch_size, capacity=30, num_threads=8, min_after_dequeue=0)\n",
    "        \n",
    "\n",
    "    # Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "        train_accuracy = 0\n",
    "        \n",
    "        print(\"epoch: \" + str(epoch))\n",
    "    \n",
    "        for batch_index in range(int(88./batch_size)):\n",
    "            #print(\"batch \" + str(batch_index))\n",
    "            \n",
    "            img, lbl = sess.run([images, labels])\n",
    "\n",
    "            #print(img[0])\n",
    "            # Get a batch of images and labels\n",
    "            \n",
    "            \n",
    "            #print(img.shape)\n",
    "            img_right_format = img.reshape((batch_size, -1))\n",
    "            #print(img_right_format.shape)\n",
    "            #print(result.shape)\n",
    "            #pixel_lists = img.reshape(img.shape[:-3] + (-1,3))\n",
    "            #result = pixel_lists[:, :, 0]\n",
    "            #print(result.shape)\n",
    "            \n",
    "            #print(lbl.shape)\n",
    "            \n",
    "            # this is lbl #a = np.array([1, 0, 3])\n",
    "            b = np.zeros((batch_size, 89))\n",
    "            b[np.arange(batch_size), lbl] = 1\n",
    "            b = np.delete(b, -1, axis=1)\n",
    "            \n",
    "            #print(\"b - shape:\", b.shape)\n",
    "            \n",
    "            #print(\"b:\", b)\n",
    "            \n",
    "            \n",
    "            #print(pixel_lists.shape)\n",
    "            \n",
    "            x_batch = img_right_format\n",
    "            y_true_batch = b\n",
    "            \n",
    "            #print(type(x_batch))\n",
    "            #print(x_batch.shape)\n",
    "            #print(type(y_true_batch))\n",
    "            #print(y_true_batch.shape)\n",
    "            \n",
    "            # Put the batch into a dict with the proper names for placeholder variables\n",
    "            feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "            \n",
    "            # Run the optimizer using this batch of training data.\n",
    "            sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Calculate the accuracy on the batch of training data\n",
    "            train_accuracy += sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "            print(\"Train accuracy on batch\", round(train_accuracy,5))\n",
    "            \n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            summ = sess.run(merged_summary, feed_dict=feed_dict_train)\n",
    "            writer.add_summary(summ, epoch*int(88./batch_size) + batch_index)\n",
    "\n",
    "            # Insert CNN CODE\n",
    "\n",
    "\n",
    "\n",
    "            # END CNN CODE\n",
    "\n",
    "            #print(\"Images \" + str(img))\n",
    "            #print(\"Labels \" + str(lbl))\n",
    "            #img = img.astype(np.uint8)\n",
    "            #for j in range(batch_size):\n",
    "            #    plt.subplot(4, 2, j+1)\n",
    "            #    plt.imshow(img[j, ...])\n",
    "            #    plt.title(str(lbl[j]))\n",
    "            #plt.show()\n",
    "            \n",
    "        train_accuracy /= int(88./batch_size)\n",
    "        \n",
    "        # Generate summary and validate the model on the entire validation set\n",
    "        #summ, vali_accuracy = sess.run([merged_summary, accuracy], feed_dict={x:data.validation.images, y_true:data.validation.labels})\n",
    "        writer1.add_summary(summ, epoch)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(round(end_time-start_time, 2))+\" seconds\")\n",
    "        print(\"\\tAccuracy:\")\n",
    "        print (\"\\t- Training Accuracy:\\t{}\".format(round(train_accuracy,2)))\n",
    "        #print (\"\\t- Validation Accuracy:\\t{}\".format(vali_accuracy))\n",
    "        \n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "\n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    \n",
    "    # trying to get a prediction\n",
    "    \n",
    "    im = img[0].reshape((1, -1))\n",
    "    print(\"corresponding label: \", lbl[0])\n",
    "    \n",
    "    feed_dict = {x: im}\n",
    "    classification = sess.run(y_pred_cls, feed_dict=feed_dict)\n",
    "    #train_accuracy += sess.run(accuracy, feed_dict=feed_dict)\n",
    "    print(classification)\n",
    "    \n",
    "    \n",
    "    print(\"wrote test-dataset stuff into \" + str(writer))\n",
    "    sess.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
