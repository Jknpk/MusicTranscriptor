{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Convolutional Neural Network - TensorFlow </h1><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data)\n",
    "\n",
    "#print(\"Size of:\")\n",
    "#print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "#print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "#print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Placeholder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-73aff66ff391>:8: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "# Placeholder variable for the input images\n",
    "x = tf.placeholder(tf.float32, shape=[None, 224*224], name='X')\n",
    "# Reshape it into [num_images, img_height, img_width, num_channels]\n",
    "x_image = tf.reshape(x, [-1, 224, 224, 1])\n",
    "\n",
    "# Placeholder variable for the true labels associated with the images\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 88], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for creating a new Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input, num_input_channels, filter_size, num_filters, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # Shape of the filter-weights for the convolution\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "        # Create new weights (filters) with the given shape\n",
    "        weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "        # Create new biases, one for each filter\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.conv2d(input=input, filter=weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # Add the biases to the results of the convolution.\n",
    "        layer += biases\n",
    "        \n",
    "        return layer, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for creating a new Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_pool_layer(input, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.max_pool(value=input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for creating a new ReLU Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_relu_layer(input, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.relu(input)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for creating a new Fully connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input, num_inputs, num_outputs, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "\n",
    "        # Create new weights and biases.\n",
    "        weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "        \n",
    "        # Multiply the input and weights, and then add the bias-values.\n",
    "        layer = tf.matmul(input, weights) + biases\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features:\n",
      "4704\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Layer 1\n",
    "layer_conv1, weights_conv1 = new_conv_layer(input=x_image, num_input_channels=1, filter_size=5, num_filters=6, name =\"conv1\")\n",
    "\n",
    "# Pooling Layer 1\n",
    "layer_pool1 = new_pool_layer(layer_conv1, name=\"pool1\")\n",
    "\n",
    "# RelU layer 1\n",
    "layer_relu1 = new_relu_layer(layer_pool1, name=\"relu1\")\n",
    "\n",
    "# Convolutional Layer 2\n",
    "layer_conv2, weights_conv2 = new_conv_layer(input=layer_relu1, num_input_channels=6, filter_size=5, num_filters=12, name= \"conv2\")\n",
    "\n",
    "# Pooling Layer 2\n",
    "layer_pool2 = new_pool_layer(layer_conv2, name=\"pool2\")\n",
    "\n",
    "# RelU layer 2\n",
    "layer_relu2 = new_relu_layer(layer_pool2, name=\"relu2\")\n",
    "\n",
    "# Convolutional Layer 3\n",
    "layer_conv3, weights_conv3 = new_conv_layer(input=layer_relu2, num_input_channels=12, filter_size=5, num_filters=24, name= \"conv3\")\n",
    "\n",
    "# Pooling Layer 3\n",
    "layer_pool3 = new_pool_layer(layer_conv3, name=\"pool3\")\n",
    "\n",
    "# RelU layer 3\n",
    "layer_relu3 = new_relu_layer(layer_pool3, name=\"relu3\")\n",
    "\n",
    "# Convolutional Layer 4\n",
    "layer_conv4, weights_conv4 = new_conv_layer(input=layer_relu3, num_input_channels=24, filter_size=5, num_filters=48, name= \"conv4\")\n",
    "\n",
    "# Pooling Layer 4\n",
    "layer_pool4 = new_pool_layer(layer_conv4, name=\"pool4\")\n",
    "\n",
    "# RelU layer 4\n",
    "layer_relu4 = new_relu_layer(layer_pool4, name=\"relu4\")\n",
    "\n",
    "# Convolutional Layer 5\n",
    "layer_conv5, weights_conv5 = new_conv_layer(input=layer_relu4, num_input_channels=48, filter_size=5, num_filters=96, name= \"conv5\")\n",
    "\n",
    "# Pooling Layer 5\n",
    "layer_pool5 = new_pool_layer(layer_conv5, name=\"pool5\")\n",
    "\n",
    "# RelU layer 5\n",
    "layer_relu5 = new_relu_layer(layer_pool5, name=\"relu5\")\n",
    "\n",
    "# Flatten Layer\n",
    "num_features = layer_relu5.get_shape()[1:4].num_elements()\n",
    "layer_flat = tf.reshape(layer_relu5, [-1, num_features])\n",
    "\n",
    "print(\"Num Features:\")\n",
    "print(num_features)                             \n",
    "                             \n",
    "# Fully-Connected Layer 1\n",
    "layer_fc1 = new_fc_layer(layer_flat, num_inputs=num_features, num_outputs=1000, name=\"fc1\")\n",
    "\n",
    "# RelU layer 3\n",
    "layer_relu6 = new_relu_layer(layer_fc1, name=\"relu6\")\n",
    "\n",
    "# Fully-Connected Layer 2\n",
    "layer_fc2 = new_fc_layer(input=layer_relu6, num_inputs=1000, num_outputs=88, name=\"fc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "# Use Softmax function to normalize the output\n",
    "with tf.variable_scope(\"Softmax\"):\n",
    "    y_pred = tf.nn.softmax(layer_fc2)\n",
    "    y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "    print('Hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-0fd2322922db>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Cross entropy cost function\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)\n",
    "    cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Adam Optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_prediction\n",
    "with tf.name_scope(\"correct_prediction\"):\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(\"Training_FileWriter/\")\n",
    "writer1 = tf.summary.FileWriter(\"Validation_FileWriter/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cost and accuracy to summary\n",
    "tf.summary.scalar('loss', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 88\n",
    "traindata_path = 'train.tfrecords'  # address to save the hdf5 file\n",
    "testdata_path = 'test.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440.0\n"
     ]
    }
   ],
   "source": [
    "totalTrainSamples = sum(1 for _ in tf.python_io.tf_record_iterator(traindata_path))*1.0\n",
    "print(totalTrainSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "SIZE: Tensor(\"Size_1:0\", shape=(), dtype=int32)\n",
      "epoch: 0\n",
      "Train accuracy on batch 0.03409\n",
      "Train accuracy on batch 0.05682\n",
      "Train accuracy on batch 0.05682\n",
      "Train accuracy on batch 0.06818\n",
      "Train accuracy on batch 0.09091\n",
      "Epoch 1 completed : Time usage 1.68 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.02\n",
      "epoch: 1\n",
      "Train accuracy on batch 0.0\n",
      "Train accuracy on batch 0.01136\n",
      "Train accuracy on batch 0.03409\n",
      "Train accuracy on batch 0.04545\n",
      "Train accuracy on batch 0.07955\n",
      "Epoch 2 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.02\n",
      "epoch: 2\n",
      "Train accuracy on batch 0.02273\n",
      "Train accuracy on batch 0.07955\n",
      "Train accuracy on batch 0.07955\n",
      "Train accuracy on batch 0.10227\n",
      "Train accuracy on batch 0.125\n",
      "Epoch 3 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.03\n",
      "epoch: 3\n",
      "Train accuracy on batch 0.02273\n",
      "Train accuracy on batch 0.07955\n",
      "Train accuracy on batch 0.125\n",
      "Train accuracy on batch 0.14773\n",
      "Train accuracy on batch 0.20455\n",
      "Epoch 4 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.04\n",
      "epoch: 4\n",
      "Train accuracy on batch 0.05682\n",
      "Train accuracy on batch 0.14773\n",
      "Train accuracy on batch 0.23864\n",
      "Train accuracy on batch 0.27273\n",
      "Train accuracy on batch 0.34091\n",
      "Epoch 5 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.07\n",
      "epoch: 5\n",
      "Train accuracy on batch 0.06818\n",
      "Train accuracy on batch 0.13636\n",
      "Train accuracy on batch 0.21591\n",
      "Train accuracy on batch 0.29545\n",
      "Train accuracy on batch 0.39773\n",
      "Epoch 6 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.08\n",
      "epoch: 6\n",
      "Train accuracy on batch 0.11364\n",
      "Train accuracy on batch 0.22727\n",
      "Train accuracy on batch 0.34091\n",
      "Train accuracy on batch 0.45455\n",
      "Train accuracy on batch 0.61364\n",
      "Epoch 7 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.12\n",
      "epoch: 7\n",
      "Train accuracy on batch 0.17045\n",
      "Train accuracy on batch 0.38636\n",
      "Train accuracy on batch 0.56818\n",
      "Train accuracy on batch 0.71591\n",
      "Train accuracy on batch 0.93182\n",
      "Epoch 8 completed : Time usage 1.26 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.19\n",
      "epoch: 8\n",
      "Train accuracy on batch 0.21591\n",
      "Train accuracy on batch 0.46591\n",
      "Train accuracy on batch 0.75\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.25\n",
      "Epoch 9 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.25\n",
      "epoch: 9\n",
      "Train accuracy on batch 0.29545\n",
      "Train accuracy on batch 0.64773\n",
      "Train accuracy on batch 1.0\n",
      "Train accuracy on batch 1.30682\n",
      "Train accuracy on batch 1.70455\n",
      "Epoch 10 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.34\n",
      "epoch: 10\n",
      "Train accuracy on batch 0.375\n",
      "Train accuracy on batch 0.81818\n",
      "Train accuracy on batch 1.22727\n",
      "Train accuracy on batch 1.64773\n",
      "Train accuracy on batch 2.15909\n",
      "Epoch 11 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.43\n",
      "epoch: 11\n",
      "Train accuracy on batch 0.46591\n",
      "Train accuracy on batch 1.01136\n",
      "Train accuracy on batch 1.5\n",
      "Train accuracy on batch 2.03409\n",
      "Train accuracy on batch 2.60227\n",
      "Epoch 12 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.52\n",
      "epoch: 12\n",
      "Train accuracy on batch 0.48864\n",
      "Train accuracy on batch 1.11364\n",
      "Train accuracy on batch 1.69318\n",
      "Train accuracy on batch 2.31818\n",
      "Train accuracy on batch 2.93182\n",
      "Epoch 13 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.59\n",
      "epoch: 13\n",
      "Train accuracy on batch 0.625\n",
      "Train accuracy on batch 1.28409\n",
      "Train accuracy on batch 1.93182\n",
      "Train accuracy on batch 2.60227\n",
      "Train accuracy on batch 3.28409\n",
      "Epoch 14 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.66\n",
      "epoch: 14\n",
      "Train accuracy on batch 0.71591\n",
      "Train accuracy on batch 1.43182\n",
      "Train accuracy on batch 2.20455\n",
      "Train accuracy on batch 2.94318\n",
      "Train accuracy on batch 3.71591\n",
      "Epoch 15 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.74\n",
      "epoch: 15\n",
      "Train accuracy on batch 0.78409\n",
      "Train accuracy on batch 1.56818\n",
      "Train accuracy on batch 2.40909\n",
      "Train accuracy on batch 3.21591\n",
      "Train accuracy on batch 4.01136\n",
      "Epoch 16 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.8\n",
      "epoch: 16\n",
      "Train accuracy on batch 0.84091\n",
      "Train accuracy on batch 1.67045\n",
      "Train accuracy on batch 2.54545\n",
      "Train accuracy on batch 3.42045\n",
      "Train accuracy on batch 4.23864\n",
      "Epoch 17 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.85\n",
      "epoch: 17\n",
      "Train accuracy on batch 0.875\n",
      "Train accuracy on batch 1.78409\n",
      "Train accuracy on batch 2.68182\n",
      "Train accuracy on batch 3.60227\n",
      "Train accuracy on batch 4.47727\n",
      "Epoch 18 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.9\n",
      "epoch: 18\n",
      "Train accuracy on batch 0.93182\n",
      "Train accuracy on batch 1.81818\n",
      "Train accuracy on batch 2.76136\n",
      "Train accuracy on batch 3.72727\n",
      "Train accuracy on batch 4.63636\n",
      "Epoch 19 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.93\n",
      "epoch: 19\n",
      "Train accuracy on batch 0.94318\n",
      "Train accuracy on batch 1.875\n",
      "Train accuracy on batch 2.875\n",
      "Train accuracy on batch 3.84091\n",
      "Train accuracy on batch 4.79545\n",
      "Epoch 20 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.96\n",
      "epoch: 20\n",
      "Train accuracy on batch 0.93182\n",
      "Train accuracy on batch 1.90909\n",
      "Train accuracy on batch 2.90909\n",
      "Train accuracy on batch 3.88636\n",
      "Train accuracy on batch 4.86364\n",
      "Epoch 21 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.97\n",
      "epoch: 21\n",
      "Train accuracy on batch 0.95455\n",
      "Train accuracy on batch 1.93182\n",
      "Train accuracy on batch 2.93182\n",
      "Train accuracy on batch 3.92045\n",
      "Train accuracy on batch 4.89773\n",
      "Epoch 22 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.98\n",
      "epoch: 22\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.95455\n",
      "Train accuracy on batch 2.95455\n",
      "Train accuracy on batch 3.94318\n",
      "Train accuracy on batch 4.93182\n",
      "Epoch 23 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 23\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 24 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 24\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 25 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 25\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 26 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 26\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 27 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 27\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 28 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 28\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 29 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 29\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 30 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 30\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 31 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 31\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 32 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 33 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 33\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 34 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 34\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 35 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 35\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 36 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 36\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 37 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 37\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 38 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 38\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 39 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 39\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 40 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 40\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 41 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 41\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 42 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 42\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 43 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 43\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 44 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 44\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 45 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 45\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 46 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 46\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 47 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 47\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 48 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 48\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 49 completed : Time usage 1.28 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "epoch: 49\n",
      "Train accuracy on batch 0.96591\n",
      "Train accuracy on batch 1.96591\n",
      "Train accuracy on batch 2.96591\n",
      "Train accuracy on batch 3.95455\n",
      "Train accuracy on batch 4.94318\n",
      "Epoch 50 completed : Time usage 1.27 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.99\n",
      "Test accuracy:  0.4659091\n",
      "True note  30 Classified: [18]\n",
      "True note  79 Classified: [79]\n",
      "5 biggest numbers (biggest last): [0.03974108 0.07423291 0.11795158 0.190836   0.543602  ]\n",
      "True note  72 Classified: [72]\n",
      "5 biggest numbers (biggest last): [0.0669082  0.07330992 0.07902746 0.21407159 0.4548814 ]\n",
      "True note  58 Classified: [58]\n",
      "5 biggest numbers (biggest last): [9.2564696e-05 1.4559126e-04 6.3412689e-04 7.3616505e-02 9.2537177e-01]\n",
      "True note  5 Classified: [7]\n",
      "True note  63 Classified: [63]\n",
      "5 biggest numbers (biggest last): [0.00549983 0.01683366 0.05639305 0.27804235 0.63000065]\n",
      "True note  82 Classified: [82]\n",
      "5 biggest numbers (biggest last): [0.0145052  0.02685617 0.03381971 0.07340792 0.8233847 ]\n",
      "True note  64 Classified: [64]\n",
      "5 biggest numbers (biggest last): [0.02497399 0.04062477 0.139684   0.2862826  0.42966908]\n",
      "True note  57 Classified: [58]\n",
      "almost correctly classifies: [0.2862826  0.42966908]\n",
      "True note  1 Classified: [21]\n",
      "True note  61 Classified: [62]\n",
      "almost correctly classifies: [0.2862826  0.42966908]\n",
      "True note  11 Classified: [8]\n",
      "True note  18 Classified: [13]\n",
      "True note  28 Classified: [34]\n",
      "True note  48 Classified: [50]\n",
      "True note  37 Classified: [38]\n",
      "almost correctly classifies: [0.2862826  0.42966908]\n",
      "True note  66 Classified: [66]\n",
      "5 biggest numbers (biggest last): [5.1455783e-05 6.2686187e-05 9.7726232e-05 2.6393382e-04 9.9940479e-01]\n",
      "True note  80 Classified: [80]\n",
      "5 biggest numbers (biggest last): [0.02426443 0.04204981 0.14020897 0.1622348  0.53909606]\n",
      "True note  24 Classified: [33]\n",
      "True note  56 Classified: [50]\n"
     ]
    }
   ],
   "source": [
    "#tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    \n",
    "    feature = {'train/image': tf.FixedLenFeature([], tf.string),\n",
    "               'train/label': tf.FixedLenFeature([], tf.int64)}\n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([traindata_path], num_epochs=num_epochs)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['train/image'], tf.uint8)\n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['train/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, [224, 224])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Handle test data almost the same way\n",
    "    \n",
    "    featureTest =  {'test/image': tf.FixedLenFeature([], tf.string),\n",
    "               'test/label': tf.FixedLenFeature([], tf.int64)}\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer([testdata_path], num_epochs=1)\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    featuresTest = tf.parse_single_example(serialized_example, features=featureTest)\n",
    "    \n",
    "    image_test = tf.decode_raw(featuresTest['test/image'], tf.uint8)\n",
    "    print(type(image), type(label))\n",
    "    image_test = tf.reshape(image_test, [224, 224])\n",
    "    label_test = tf.cast(featuresTest['test/label'], tf.int32)\n",
    "    \n",
    "    # Any preprocessing here ...\n",
    "    \n",
    "    print(type(image), type(label))\n",
    "    \n",
    "    # Creates batches by randomly shuffling tensors\n",
    "    images, labels = tf.train.shuffle_batch([image, label], batch_size=batch_size, capacity=88, num_threads=8, min_after_dequeue=0)\n",
    "    print(\"SIZE:\", tf.size(labels))\n",
    "  \n",
    "\n",
    "    images_test, labels_test = tf.train.batch([image_test, label_test], batch_size=88, capacity=88, num_threads=8)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "        train_accuracy = 0\n",
    "        \n",
    "        print(\"epoch: \" + str(epoch))\n",
    "    \n",
    "        for batch_index in range(int(totalTrainSamples/batch_size)):\n",
    "            #print(\"batch \" + str(batch_index))\n",
    "            \n",
    "            img, lbl = sess.run([images, labels])\n",
    "            #print(img, lbl)\n",
    "\n",
    "            #print(img[0])\n",
    "            # Get a batch of images and labels\n",
    "            \n",
    "            \n",
    "            #print(img.shape)\n",
    "            img_right_format = img.reshape((batch_size, -1))\n",
    "            #print(img_right_format.shape)\n",
    "            #print(result.shape)\n",
    "            #pixel_lists = img.reshape(img.shape[:-3] + (-1,3))\n",
    "            #result = pixel_lists[:, :, 0]\n",
    "            #print(result.shape)\n",
    "            \n",
    "            #print(lbl.shape)\n",
    "            \n",
    "            # this is lbl #a = np.array([1, 0, 3])\n",
    "            b = np.zeros((batch_size, 89))\n",
    "            b[np.arange(batch_size), lbl] = 1\n",
    "            b = np.delete(b, -1, axis=1)\n",
    "            \n",
    "            #print(\"b - shape:\", b.shape)\n",
    "            \n",
    "            #print(\"b:\", b)\n",
    "            \n",
    "            \n",
    "            #print(pixel_lists.shape)\n",
    "            \n",
    "            x_batch = img_right_format\n",
    "            y_true_batch = b\n",
    "            \n",
    "            #print(type(x_batch))\n",
    "            #print(x_batch.shape)\n",
    "            #print(type(y_true_batch))\n",
    "            #print(y_true_batch.shape)\n",
    "            \n",
    "            # Put the batch into a dict with the proper names for placeholder variables\n",
    "            feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "            \n",
    "            # Run the optimizer using this batch of training data.\n",
    "            sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Calculate the accuracy on the batch of training data\n",
    "            train_accuracy += sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "            print(\"Train accuracy on batch\", round(train_accuracy,5))\n",
    "            \n",
    "            # Generate summary with the current batch of data and write to file\n",
    "            summ = sess.run(merged_summary, feed_dict=feed_dict_train)\n",
    "            writer.add_summary(summ, epoch*int(totalTrainSamples/batch_size) + batch_index)\n",
    "\n",
    "            # Insert CNN CODE\n",
    "\n",
    "\n",
    "\n",
    "            # END CNN CODE\n",
    "\n",
    "            #print(\"Images \" + str(img))\n",
    "            #print(\"Labels \" + str(lbl))\n",
    "            #img = img.astype(np.uint8)\n",
    "            #for j in range(batch_size):\n",
    "            #    plt.subplot(4, 2, j+1)\n",
    "            #    plt.imshow(img[j, ...])\n",
    "            #    plt.title(str(lbl[j]))\n",
    "            #plt.show()\n",
    "            \n",
    "        train_accuracy /= int(totalTrainSamples/batch_size)\n",
    "        \n",
    "        # Generate summary and validate the model on the entire validation set\n",
    "        #summ, vali_accuracy = sess.run([merged_summary, accuracy], feed_dict={x:data.validation.images, y_true:data.validation.labels})\n",
    "        writer1.add_summary(summ, epoch)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(round(end_time-start_time, 2))+\" seconds\")\n",
    "        print(\"\\tAccuracy:\")\n",
    "        print (\"\\t- Training Accuracy:\\t{}\".format(round(train_accuracy,2)))\n",
    "        #print (\"\\t- Validation Accuracy:\\t{}\".format(vali_accuracy))\n",
    "        \n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "\n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    \n",
    "    \n",
    "    # try to get a whole test case running\n",
    "    img, lbl = sess.run([images_test, labels_test])\n",
    "    #print(img, lbl)\n",
    "    img_right_format = img.reshape((88, -1))\n",
    "    b = np.zeros((88, 89))\n",
    "    b[np.arange(88), lbl] = 1\n",
    "    b = np.delete(b, -1, axis=1)\n",
    "    x_batch = img_right_format\n",
    "    y_true_batch = b\n",
    "    feed_dict_test = {x: x_batch, y_true: y_true_batch}\n",
    "    test_accuracy = sess.run(accuracy, feed_dict=feed_dict_test)\n",
    "    print(\"Test accuracy: \", test_accuracy)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for note in range(0, 20, 1):\n",
    "        # trying to get a prediction\n",
    "        im = img[note].reshape((1, -1))\n",
    "        feed_dict = {x: im}\n",
    "        classifications = sess.run(y_pred, feed_dict=feed_dict)\n",
    "        classification = sess.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        \n",
    "        print(\"True note \", lbl[note], \"Classified:\", classification) \n",
    "        if classification[0] == lbl[note]:\n",
    "            flat = classifications.flatten()\n",
    "            flat.sort()\n",
    "            print(\"5 biggest numbers (biggest last):\", flat[-5:])\n",
    "        elif abs(classification[0] - lbl[note]) < 2:\n",
    "            print(\"almost correctly classifies:\", flat[-2:])\n",
    "          \n",
    "\n",
    "    \n",
    "    sess.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#tf.reset_default_graph()\\nwith tf.Session() as sess:\\n    \\n    # Initialize all variables\\n    sess.run(tf.global_variables_initializer())\\n    \\n    # Add the model graph to TensorBoard\\n    #writer.add_graph(sess.graph)\\n    \\n    print(\"Hello1\")\\n    # Handle test data almost the same way\\n    \\n    featureTest =  {\\'test/image\\': tf.FixedLenFeature([], tf.string),\\n               \\'test/label\\': tf.FixedLenFeature([], tf.int64)}\\n    \\n    filename_queue = tf.train.string_input_producer([testdata_path], num_epochs=1)\\n    reader = tf.TFRecordReader()\\n    _, serialized_example = reader.read(filename_queue)\\n    featuresTest = tf.parse_single_example(serialized_example, features=featureTest)\\n    \\n    image_test = tf.decode_raw(featuresTest[\\'test/image\\'], tf.uint8)\\n    image_test = tf.reshape(image_test, [224, 224])\\n    label_test = tf.cast(featuresTest[\\'test/label\\'], tf.int32)\\n    \\n    # Any preprocessing here ...\\n    \\n    images_test, labels_test = tf.train.batch([image_test, label_test], batch_size=88, capacity=88, num_threads=8)\\n    \\n\\n    # Initialize all global and local variables\\n    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\\n\\n    sess.run(init_op)\\n    print(\"Hello1\") \\n    \\n    # try to get a whole test case running\\n    img, lbl = sess.run([images_test, labels_test])\\n    print(img, lbl)\\n    img_right_format = img.reshape((88, -1))\\n    b = np.zeros((88, 89))\\n    b[np.arange(88), lbl] = 1\\n    b = np.delete(b, -1, axis=1)\\n    x_batch = img_right_format\\n    y_true_batch = b\\n    feed_dict_test = {x: x_batch, y_true: y_true_batch}\\n    test_accuracy = sess.run(accuracy, feed_dict=feed_dict_test)\\n    print(\"Test accuracy: \", test_accuracy)\\n    \\n    \\n    # trying to get a prediction\\n    #im = img[0].reshape((1, -1))\\n    #print(\"corresponding label: \", lbl[0])\\n    #feed_dict = {x: im}\\n    #classification = sess.run(y_pred_cls, feed_dict=feed_dict)\\n    #print(classification)   \\n    #print(\"wrote test-dataset stuff into \" + str(writer))\\n    \\n    sess.close()\\n    \\n    '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Add the model graph to TensorBoard\n",
    "    #writer.add_graph(sess.graph)\n",
    "    \n",
    "    print(\"Hello1\")\n",
    "    # Handle test data almost the same way\n",
    "    \n",
    "    featureTest =  {'test/image': tf.FixedLenFeature([], tf.string),\n",
    "               'test/label': tf.FixedLenFeature([], tf.int64)}\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer([testdata_path], num_epochs=1)\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    featuresTest = tf.parse_single_example(serialized_example, features=featureTest)\n",
    "    \n",
    "    image_test = tf.decode_raw(featuresTest['test/image'], tf.uint8)\n",
    "    image_test = tf.reshape(image_test, [224, 224])\n",
    "    label_test = tf.cast(featuresTest['test/label'], tf.int32)\n",
    "    \n",
    "    # Any preprocessing here ...\n",
    "    \n",
    "    images_test, labels_test = tf.train.batch([image_test, label_test], batch_size=88, capacity=88, num_threads=8)\n",
    "    \n",
    "\n",
    "    # Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    sess.run(init_op)\n",
    "    print(\"Hello1\") \n",
    "    \n",
    "    # try to get a whole test case running\n",
    "    img, lbl = sess.run([images_test, labels_test])\n",
    "    print(img, lbl)\n",
    "    img_right_format = img.reshape((88, -1))\n",
    "    b = np.zeros((88, 89))\n",
    "    b[np.arange(88), lbl] = 1\n",
    "    b = np.delete(b, -1, axis=1)\n",
    "    x_batch = img_right_format\n",
    "    y_true_batch = b\n",
    "    feed_dict_test = {x: x_batch, y_true: y_true_batch}\n",
    "    test_accuracy = sess.run(accuracy, feed_dict=feed_dict_test)\n",
    "    print(\"Test accuracy: \", test_accuracy)\n",
    "    \n",
    "    \n",
    "    # trying to get a prediction\n",
    "    #im = img[0].reshape((1, -1))\n",
    "    #print(\"corresponding label: \", lbl[0])\n",
    "    #feed_dict = {x: im}\n",
    "    #classification = sess.run(y_pred_cls, feed_dict=feed_dict)\n",
    "    #print(classification)   \n",
    "    #print(\"wrote test-dataset stuff into \" + str(writer))\n",
    "    \n",
    "    sess.close()\n",
    "    \n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
